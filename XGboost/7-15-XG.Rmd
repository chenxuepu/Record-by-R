---
title: "XGboost"
author: '610811101'
date: "2020/7/15"
output:
  html_document:
    code_folding: hide
    df_print: paged
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
---



```{r include=FALSE}
library(mda)
library(OneR)
library(magrittr)
library(iml)
library(caret)
library(xgboost)
library(MASS)
library("highcharter")
library(ROCR)
library(ROCit)
library(plotROC)
library(boot)
library(randomForest)
library(mvtnorm)
# load("G:/我的雲端硬碟/BGG/data_test.RData")
# load("G:/我的雲端硬碟/BGG/data_7wonder_2.RData")
```



# 資料生成跑XGboost Feature Importances  




## 資料一 (部分相關)      
就算只有一部分資料是相關的，XGboost的成效會仍然會變差。

$x_{1 \sim 5}\sim MN(\mu_1 , \Sigma_1 )$  
$\mu_1=(0,0,0,0,0,0,0,0,0,0)$  
$\Sigma_1 =  A^TDA$   

$$D = \begin{pmatrix}
1 & 0 & 0 & 0 & 0 \\ 
0 &  1& 0 & 0 & 0 \\ 
0 &  0& 1 & 0 & 0 \\ 
0 &  0& 0 & 1 & 0 \\ 
0 &  0& 0 & 0 & 1 
\end{pmatrix}$$   

$$A = \begin{pmatrix}
0 & 2 & 2 & -2 & -1 \\ 
0 &  1& 0 & -2 & -2 \\ 
-1 &  -2& 0 & 2 & 0 \\ 
-1 &  -1& -2 & 0 & 1 \\ 
0 &  0& 1 & -1 & -2 
\end{pmatrix}$$  

$x_{6 \sim 10}\sim MN(\mu_2 , \Sigma_2 )$  
$\mu_2=(0,0,0,0,0,0,0,0,0,0)$ 

$$\Sigma_2 = \begin{pmatrix}
1 & 0 & 0 & 0 & 0 \\ 
0 &  1& 0 & 0 & 0 \\ 
0 &  0& 1 & 0 & 0 \\ 
0 &  0& 0 & 1 & 0 \\ 
0 &  0& 0 & 0 & 1 
\end{pmatrix}$$  
  


$x_{11} \sim N(0,1)$        

$y=10x_1+5x_2-3x_3+4x_4+8x_5+10x_6+5x_7-3x_8+4x_9+8x_{10}+\epsilon$  

$\epsilon \sim N(0,4)$  

### 第一次     

```{r}
set.seed(123)
a <- matrix(sample(-2:2,25,replace = T),5,5)
sigmas <- t(a)%*%diag(1,5)%*%a
set.seed(1253)
x <- rmvnorm(n = 1000,mean = c(0,0,0,0,0),sigma = sigmas)
set.seed(173)
x2 <- rmvnorm(n = 1000,mean = c(0,0,0,0,0),sigma = diag(1,5))
set.seed(59)
x_11 <- rnorm(n = 1000)
set.seed(5)
sd <- rnorm(1000,sd = 2)
y <- 10*x[,1]+5*x[,2]-3*x[,3]+4*x[,4]+8*x[,5]+10*x2[,1]+5*x2[,2]-3*x2[,3]+4*x2[,4]+8*x2[,5]+sd
sim <- data.frame(y,x,x2,x_11)


set.seed(192753)
x <- rmvnorm(n = 1000,mean = c(0,0,0,0,0),sigma = sigmas)
set.seed(1783)
x2 <- rmvnorm(n = 1000,mean = c(0,0,0,0,0),sigma = diag(1,5))
set.seed(599)
x_11 <- rnorm(n = 1000)
set.seed(54)
sd <- rnorm(1000,sd = 2)
y <- 10*x[,1]+5*x[,2]-3*x[,3]+4*x[,4]+8*x[,5]+10*x2[,1]+5*x2[,2]-3*x2[,3]+4*x2[,4]+8*x2[,5]+sd
sim_2 <- data.frame(y,x,x2,x_11)
names(sim) <- c("y",paste0("x",1:11))
names(sim_2) <- c("y",paste0("x",1:11))
print("直接將生成的資料放進回歸中測試")
lm(y~.,data = sim) %>% summary()
label  <- lm(y~.,data = sim) %>% predict(sim_2)
print("MSE")
mean((sim_2$y-label)^2)
print("xgboost")
xgb_test <- xgboost(data = data.matrix(sim[,-1]), 
label = sim[,"y"], 
eta = 0.5,
max_depth = 10, 
nround=25, 
subsample = 0.7,
colsample_bytree = 0.7,
objective = "reg:squarederror",
verbose = 0
)
label  <- predict(xgb_test,xgb.DMatrix(data.matrix(sim_2[,-1])))
print("MSE")
mean((sim_2$y-label)^2)

xgb.importance(model = xgb_test)

xgb.importance(model = xgb_test) %>% 
  xgb.plot.importance(top_n = 11)



```




```{r}
sim$y <- ifelse(sim$y>0,1,0)
sim_2$y <- ifelse(sim_2$y>0,1,0)
glm(y~.,family = binomial(),data = sim) %>% summary()
label  <- glm(y~.,family = binomial(),data = sim) %>% predict(sim_2,type="response")
Roc <- rocit(score=label,class=sim_2$y )

plot(Roc,values=F)

Cutoff <- which(Roc$FPR>=0.03) %>%
  min %>%
  Roc$Cutoff[.]
table(sim_2$y,label>Cutoff)


print("xgboost")
xgb_test <- xgboost(data = data.matrix(sim[,-1]), 
label = sim[,"y"], 
eta = 0.5,
max_depth = 10, 
nround=25, 
subsample = 0.7,
colsample_bytree = 0.7,
objective = "binary:logistic",
verbose = 0
)
label  <- predict(xgb_test,xgb.DMatrix(data.matrix(sim_2[,-1])))
Roc <- rocit(score=label,class=sim_2$y )

plot(Roc,values=F)


Cutoff <- which(Roc$FPR>=0.1) %>%
  min %>%
  Roc$Cutoff[.]
  
table(sim_2$y,label>Cutoff)
xgb.importance(model = xgb_test)

xgb.importance(model = xgb_test) %>% 
  xgb.plot.importance(top_n = 11)



```


### 第二次      


```{r}
set.seed(123)
a <- matrix(sample(-2:2,25,replace = T),5,5)
sigmas <- t(a)%*%diag(1,5)%*%a
set.seed(155253)
x <- rmvnorm(n = 1000,mean = c(0,0,0,0,0),sigma = sigmas)
set.seed(6173)
x2 <- rmvnorm(n = 1000,mean = c(0,0,0,0,0),sigma = diag(1,5))
set.seed(579)
x_11 <- rnorm(n = 1000)
set.seed(85)
sd <- rnorm(1000,sd = 2)
y <- 10*x[,1]+5*x[,2]-3*x[,3]+4*x[,4]+8*x[,5]+10*x2[,1]+5*x2[,2]-3*x2[,3]+4*x2[,4]+8*x2[,5]+sd
sim <- data.frame(y,x,x2,x_11)


set.seed(19923)
x <- rmvnorm(n = 1000,mean = c(0,0,0,0,0),sigma = sigmas)
set.seed(175483)
x2 <- rmvnorm(n = 1000,mean = c(0,0,0,0,0),sigma = diag(1,5))
set.seed(5969)
x_11 <- rnorm(n = 1000)
set.seed(547)
sd <- rnorm(1000,sd = 2)
y <- 10*x[,1]+5*x[,2]-3*x[,3]+4*x[,4]+8*x[,5]+10*x2[,1]+5*x2[,2]-3*x2[,3]+4*x2[,4]+8*x2[,5]+sd
sim_2 <- data.frame(y,x,x2,x_11)
names(sim) <- c("y",paste0("x",1:11))
names(sim_2) <- c("y",paste0("x",1:11))
print("直接將生成的資料放進回歸中測試")
lm(y~.,data = sim) %>% summary()
label  <- lm(y~.,data = sim) %>% predict(sim_2)
print("MSE")
mean((sim_2$y-label)^2)
print("xgboost")
xgb_test <- xgboost(data = data.matrix(sim[,-1]), 
label = sim[,"y"], 
eta = 0.5,
max_depth = 10, 
nround=25, 
subsample = 0.7,
colsample_bytree = 0.7,
objective = "reg:squarederror",
verbose = 0
)
label  <- predict(xgb_test,xgb.DMatrix(data.matrix(sim_2[,-1])))
print("MSE")
mean((sim_2$y-label)^2)

xgb.importance(model = xgb_test)

xgb.importance(model = xgb_test) %>% 
  xgb.plot.importance(top_n = 11)



```




```{r}
sim$y <- ifelse(sim$y>0,1,0)
sim_2$y <- ifelse(sim_2$y>0,1,0)
glm(y~.,family = binomial(),data = sim) %>% summary()
label  <- glm(y~.,family = binomial(),data = sim) %>% predict(sim_2,type="response")
Roc <- rocit(score=label,class=sim_2$y )

plot(Roc,values=F)

Cutoff <- which(Roc$FPR>=0.03) %>%
  min %>%
  Roc$Cutoff[.]
table(sim_2$y,label>Cutoff)


print("xgboost")
xgb_test <- xgboost(data = data.matrix(sim[,-1]), 
label = sim[,"y"], 
eta = 0.5,
max_depth = 10, 
nround=25, 
subsample = 0.7,
colsample_bytree = 0.7,
objective = "binary:logistic",
verbose = 0
)
label  <- predict(xgb_test,xgb.DMatrix(data.matrix(sim_2[,-1])))
Roc <- rocit(score=label,class=sim_2$y )

plot(Roc,values=F)


Cutoff <- which(Roc$FPR>=0.1) %>%
  min %>%
  Roc$Cutoff[.]
  
table(sim_2$y,label>Cutoff)
xgb.importance(model = xgb_test)

xgb.importance(model = xgb_test) %>% 
  xgb.plot.importance(top_n = 11)



```



### 第三次     

```{r}
set.seed(123)
a <- matrix(sample(-2:2,25,replace = T),5,5)
sigmas <- t(a)%*%diag(1,5)%*%a
set.seed(12536)
x <- rmvnorm(n = 1000,mean = c(0,0,0,0,0),sigma = sigmas)
set.seed(1783)
x2 <- rmvnorm(n = 1000,mean = c(0,0,0,0,0),sigma = diag(1,5))
set.seed(519)
x_11 <- rnorm(n = 1000)
set.seed(53)
sd <- rnorm(1000,sd = 2)
y <- 10*x[,1]+5*x[,2]-3*x[,3]+4*x[,4]+8*x[,5]+10*x2[,1]+5*x2[,2]-3*x2[,3]+4*x2[,4]+8*x2[,5]+sd
sim <- data.frame(y,x,x2,x_11)


set.seed(17773)
x <- rmvnorm(n = 1000,mean = c(0,0,0,0,0),sigma = sigmas)
set.seed(18783)
x2 <- rmvnorm(n = 1000,mean = c(0,0,0,0,0),sigma = diag(1,5))
set.seed(5994)
x_11 <- rnorm(n = 1000)
set.seed(84)
sd <- rnorm(1000,sd = 2)
y <- 10*x[,1]+5*x[,2]-3*x[,3]+4*x[,4]+8*x[,5]+10*x2[,1]+5*x2[,2]-3*x2[,3]+4*x2[,4]+8*x2[,5]+sd
sim_2 <- data.frame(y,x,x2,x_11)
names(sim) <- c("y",paste0("x",1:11))
names(sim_2) <- c("y",paste0("x",1:11))
print("直接將生成的資料放進回歸中測試")
lm(y~.,data = sim) %>% summary()
label  <- lm(y~.,data = sim) %>% predict(sim_2)
print("MSE")
mean((sim_2$y-label)^2)
print("xgboost")
xgb_test <- xgboost(data = data.matrix(sim[,-1]), 
label = sim[,"y"], 
eta = 0.5,
max_depth = 10, 
nround=25, 
subsample = 0.7,
colsample_bytree = 0.7,
objective = "reg:squarederror",
verbose = 0
)
label  <- predict(xgb_test,xgb.DMatrix(data.matrix(sim_2[,-1])))
print("MSE")
mean((sim_2$y-label)^2)

xgb.importance(model = xgb_test)

xgb.importance(model = xgb_test) %>% 
  xgb.plot.importance(top_n = 11)



```




```{r}
sim$y <- ifelse(sim$y>0,1,0)
sim_2$y <- ifelse(sim_2$y>0,1,0)
glm(y~.,family = binomial(),data = sim) %>% summary()
label  <- glm(y~.,family = binomial(),data = sim) %>% predict(sim_2,type="response")
Roc <- rocit(score=label,class=sim_2$y )

plot(Roc,values=F)

Cutoff <- which(Roc$FPR>=0.01) %>%
  min %>%
  Roc$Cutoff[.]
table(sim_2$y,label>Cutoff)


print("xgboost")
xgb_test <- xgboost(data = data.matrix(sim[,-1]), 
label = sim[,"y"], 
eta = 0.5,
max_depth = 10, 
nround=25, 
subsample = 0.7,
colsample_bytree = 0.7,
objective = "binary:logistic",
verbose = 0
)
label  <- predict(xgb_test,xgb.DMatrix(data.matrix(sim_2[,-1])))
Roc <- rocit(score=label,class=sim_2$y )

plot(Roc,values=F)


Cutoff <- which(Roc$FPR>=0.1) %>%
  min %>%
  Roc$Cutoff[.]
  
table(sim_2$y,label>Cutoff)
xgb.importance(model = xgb_test)

xgb.importance(model = xgb_test) %>% 
  xgb.plot.importance(top_n = 11)



```


## 資料二(一般項加交互作用項)    

因為回歸沒有加上交互作用項，所以兩個的預測結果都很差。

$x_{1 \sim 10}\sim MN(\mu , \Sigma )$
$\mu=(0,0,0,0,0,0,0,0,0,0)$
$$\Sigma = \begin{pmatrix}
1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\ 
0 &  1& 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\ 
0 &  0& 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\ 
0 &  0& 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0\\ 
0 &  0& 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0\\ 
0 &  0& 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0\\ 
0 &  0& 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0\\ 
0 &  0& 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0\\ 
0 &  0& 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0\\ 
0 &  0& 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1
\end{pmatrix}$$  

$x_{11} \sim N(0,1)$      

$y=10x_1+5x_2-3x_3+4x_4+8x_5-7x_6+9x_7-2x_8+5x_9-4x_{10}+10x_1x_2-7x_3x_4+\epsilon$

$\epsilon \sim N(0,4)$

### 第一次   

```{r}
set.seed(1423)
x <- rmvnorm(n = 1000,mean = c(0,0,0,0,0,0,0,0,0,0),sigma = diag(1,10))
set.seed(597)
x_11 <- rnorm(n = 1000)
set.seed(55)
sd <- rnorm(1000,sd = 2)
y <- 10*x[,1]+5*x[,2]-3*x[,3]+4*x[,4]+8*x[,5]-7*x[,6]+9*x[,7]-2*x[,8]+5*x[,9]-4*x[,10]+10*x[,1]*x[,2]-7*x[,3]*x[,4]+sd
sim <- data.frame(y,x,x_11)


set.seed(1232)
x <- rmvnorm(n = 1000,mean = c(0,0,0,0,0,0,0,0,0,0),sigma = diag(1,10))
set.seed(599)
x_11 <- rnorm(n = 1000)
set.seed(57)
sd <- rnorm(1000,sd = 2)
y <- 10*x[,1]+5*x[,2]-3*x[,3]+4*x[,4]+8*x[,5]-7*x[,6]+9*x[,7]-2*x[,8]+5*x[,9]-4*x[,10]+10*x[,1]*x[,2]-7*x[,3]*x[,4]+sd
sim_2 <- data.frame(y,x,x_11)
names(sim) <- c("y",paste0("x",1:11))
names(sim_2) <- c("y",paste0("x",1:11))
print("直接將生成的資料放進回歸中測試")
lm(y~.,data = sim) %>% summary()
label  <- lm(y~.,data = sim) %>% predict(sim_2)
print("MSE")
mean((sim_2$y-label)^2)
print("xgboost")
xgb_test <- xgboost(data = data.matrix(sim[,-1]), 
label = sim[,"y"], 
eta = 0.5,
max_depth = 10, 
nround=25, 
subsample = 0.7,
colsample_bytree = 0.7,
objective = "reg:squarederror",
verbose = 0
)
label  <- predict(xgb_test,xgb.DMatrix(data.matrix(sim_2[,-1])))
print("MSE")
mean((sim_2$y-label)^2)

xgb.importance(model = xgb_test)

xgb.importance(model = xgb_test) %>% 
  xgb.plot.importance(top_n = 11)



```




```{r}
sim$y <- ifelse(sim$y>0,1,0)
sim_2$y <- ifelse(sim_2$y>0,1,0)
glm(y~.,family = binomial(),data = sim) %>% summary()
label  <- glm(y~.,family = binomial(),data = sim) %>% predict(sim_2,type="response")
Roc <- rocit(score=label,class=sim_2$y )

plot(Roc,values=F)

Cutoff <- which(Roc$FPR>=0.1) %>%
  min %>%
  Roc$Cutoff[.]
table(sim_2$y,label>Cutoff)


print("xgboost")
xgb_test <- xgboost(data = data.matrix(sim[,-1]), 
label = sim[,"y"], 
eta = 0.5,
max_depth = 10, 
nround=25, 
subsample = 0.7,
colsample_bytree = 0.7,
objective = "binary:logistic",
verbose = 0
)
label  <- predict(xgb_test,xgb.DMatrix(data.matrix(sim_2[,-1])))
Roc <- rocit(score=label,class=sim_2$y )

plot(Roc,values=F)


Cutoff <- which(Roc$FPR>=0.1) %>%
  min %>%
  Roc$Cutoff[.]
  
table(sim_2$y,label>Cutoff)
xgb.importance(model = xgb_test)

xgb.importance(model = xgb_test) %>% 
  xgb.plot.importance(top_n = 11)



```

### 第二次      

```{r}
set.seed(17423)
x <- rmvnorm(n = 1000,mean = c(0,0,0,0,0,0,0,0,0,0),sigma = diag(1,10))
set.seed(5997)
x_11 <- rnorm(n = 1000)
set.seed(515)
sd <- rnorm(1000,sd = 2)
y <- 10*x[,1]+5*x[,2]-3*x[,3]+4*x[,4]+8*x[,5]-7*x[,6]+9*x[,7]-2*x[,8]+5*x[,9]-4*x[,10]+10*x[,1]*x[,2]-7*x[,3]*x[,4]+sd
sim <- data.frame(y,x,x_11)


set.seed(12632)
x <- rmvnorm(n = 1000,mean = c(0,0,0,0,0,0,0,0,0,0),sigma = diag(1,10))
set.seed(5998)
x_11 <- rnorm(n = 1000)
set.seed(597)
sd <- rnorm(1000,sd = 2)
y <- 10*x[,1]+5*x[,2]-3*x[,3]+4*x[,4]+8*x[,5]-7*x[,6]+9*x[,7]-2*x[,8]+5*x[,9]-4*x[,10]+10*x[,1]*x[,2]-7*x[,3]*x[,4]+sd
sim_2 <- data.frame(y,x,x_11)
names(sim) <- c("y",paste0("x",1:11))
names(sim_2) <- c("y",paste0("x",1:11))
print("直接將生成的資料放進回歸中測試")
lm(y~.,data = sim) %>% summary()
label  <- lm(y~.,data = sim) %>% predict(sim_2)
print("MSE")
mean((sim_2$y-label)^2)
print("xgboost")
xgb_test <- xgboost(data = data.matrix(sim[,-1]), 
label = sim[,"y"], 
eta = 0.5,
max_depth = 10, 
nround=25, 
subsample = 0.7,
colsample_bytree = 0.7,
objective = "reg:squarederror",
verbose = 0
)
label  <- predict(xgb_test,xgb.DMatrix(data.matrix(sim_2[,-1])))
print("MSE")
mean((sim_2$y-label)^2)

xgb.importance(model = xgb_test)

xgb.importance(model = xgb_test) %>% 
  xgb.plot.importance(top_n = 11)



```




```{r}
sim$y <- ifelse(sim$y>0,1,0)
sim_2$y <- ifelse(sim_2$y>0,1,0)
glm(y~.,family = binomial(),data = sim) %>% summary()
label  <- glm(y~.,family = binomial(),data = sim) %>% predict(sim_2,type="response")
Roc <- rocit(score=label,class=sim_2$y )

plot(Roc,values=F)

Cutoff <- which(Roc$FPR>=0.2) %>%
  min %>%
  Roc$Cutoff[.]
table(sim_2$y,label>Cutoff)


print("xgboost")
xgb_test <- xgboost(data = data.matrix(sim[,-1]), 
label = sim[,"y"], 
eta = 0.5,
max_depth = 10, 
nround=25, 
subsample = 0.7,
colsample_bytree = 0.7,
objective = "binary:logistic",
verbose = 0
)
label  <- predict(xgb_test,xgb.DMatrix(data.matrix(sim_2[,-1])))
Roc <- rocit(score=label,class=sim_2$y )

plot(Roc,values=F)


Cutoff <- which(Roc$FPR>=0.2) %>%
  min %>%
  Roc$Cutoff[.]
  
table(sim_2$y,label>Cutoff)
xgb.importance(model = xgb_test)

xgb.importance(model = xgb_test) %>% 
  xgb.plot.importance(top_n = 11)



```


### 第三次     

```{r}
set.seed(1443)
x <- rmvnorm(n = 1000,mean = c(0,0,0,0,0,0,0,0,0,0),sigma = diag(1,10))
set.seed(5697)
x_11 <- rnorm(n = 1000)
set.seed(505)
sd <- rnorm(1000,sd = 2)
y <- 10*x[,1]+5*x[,2]-3*x[,3]+4*x[,4]+8*x[,5]-7*x[,6]+9*x[,7]-2*x[,8]+5*x[,9]-4*x[,10]+10*x[,1]*x[,2]-7*x[,3]*x[,4]+sd
sim <- data.frame(y,x,x_11)


set.seed(13232)
x <- rmvnorm(n = 1000,mean = c(0,0,0,0,0,0,0,0,0,0),sigma = diag(1,10))
set.seed(509)
x_11 <- rnorm(n = 1000)
set.seed(547)
sd <- rnorm(1000,sd = 2)
y <- 10*x[,1]+5*x[,2]-3*x[,3]+4*x[,4]+8*x[,5]-7*x[,6]+9*x[,7]-2*x[,8]+5*x[,9]-4*x[,10]+10*x[,1]*x[,2]-7*x[,3]*x[,4]+sd
sim_2 <- data.frame(y,x,x_11)
names(sim) <- c("y",paste0("x",1:11))
names(sim_2) <- c("y",paste0("x",1:11))
print("直接將生成的資料放進回歸中測試")
lm(y~.,data = sim) %>% summary()
label  <- lm(y~.,data = sim) %>% predict(sim_2)
print("MSE")
mean((sim_2$y-label)^2)
print("xgboost")
xgb_test <- xgboost(data = data.matrix(sim[,-1]), 
label = sim[,"y"], 
eta = 0.5,
max_depth = 10, 
nround=25, 
subsample = 0.7,
colsample_bytree = 0.7,
objective = "reg:squarederror",
verbose = 0
)
label  <- predict(xgb_test,xgb.DMatrix(data.matrix(sim_2[,-1])))
print("MSE")
mean((sim_2$y-label)^2)

xgb.importance(model = xgb_test)

xgb.importance(model = xgb_test) %>% 
  xgb.plot.importance(top_n = 11)



```




```{r}
sim$y <- ifelse(sim$y>0,1,0)
sim_2$y <- ifelse(sim_2$y>0,1,0)
glm(y~.,family = binomial(),data = sim) %>% summary()
label  <- glm(y~.,family = binomial(),data = sim) %>% predict(sim_2,type="response")
Roc <- rocit(score=label,class=sim_2$y )

plot(Roc,values=F)

Cutoff <- which(Roc$FPR>=0.15) %>%
  min %>%
  Roc$Cutoff[.]
table(sim_2$y,label>Cutoff)


print("xgboost")
xgb_test <- xgboost(data = data.matrix(sim[,-1]), 
label = sim[,"y"], 
eta = 0.5,
max_depth = 10, 
nround=25, 
subsample = 0.7,
colsample_bytree = 0.7,
objective = "binary:logistic",
verbose = 0
)
label  <- predict(xgb_test,xgb.DMatrix(data.matrix(sim_2[,-1])))
Roc <- rocit(score=label,class=sim_2$y )

plot(Roc,values=F)


Cutoff <- which(Roc$FPR>=0.1) %>%
  min %>%
  Roc$Cutoff[.]
  
table(sim_2$y,label>Cutoff)
xgb.importance(model = xgb_test)

xgb.importance(model = xgb_test) %>% 
  xgb.plot.importance(top_n = 11)



```



## 資料三(只有交互作用項)   

回歸表現得比XGboost還差，XGboost有大概抓到是那些變數。

$x_{1 \sim 10}\sim MN(\mu , \Sigma )$
$\mu=(0,0,0,0,0,0,0,0,0,0)$
$$\Sigma = \begin{pmatrix}
1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\ 
0 &  1& 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\ 
0 &  0& 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\ 
0 &  0& 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0\\ 
0 &  0& 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0\\ 
0 &  0& 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0\\ 
0 &  0& 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0\\ 
0 &  0& 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0\\ 
0 &  0& 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0\\ 
0 &  0& 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1
\end{pmatrix}$$  

$x_{11} \sim N(0,1)$      

$y=+10x_1x_2-7x_3x_4-8x_6x_9+\epsilon$

$\epsilon \sim N(0,4)$

### 第一次   

```{r}
set.seed(1423)
x <- rmvnorm(n = 1000,mean = c(0,0,0,0,0,0,0,0,0,0),sigma = diag(1,10))
set.seed(597)
x_11 <- rnorm(n = 1000)
set.seed(55)
sd <- rnorm(1000,sd = 2)
y <- 10*x[,1]*x[,2]-7*x[,3]*x[,4]-8*x[,6]*x[,9]+sd
sim <- data.frame(y,x,x_11)


set.seed(1232)
x <- rmvnorm(n = 1000,mean = c(0,0,0,0,0,0,0,0,0,0),sigma = diag(1,10))
set.seed(599)
x_11 <- rnorm(n = 1000)
set.seed(57)
sd <- rnorm(1000,sd = 2)
y <- 10*x[,1]*x[,2]-7*x[,3]*x[,4]-8*x[,6]*x[,9]+sd
sim_2 <- data.frame(y,x,x_11)
names(sim) <- c("y",paste0("x",1:11))
names(sim_2) <- c("y",paste0("x",1:11))
print("直接將生成的資料放進回歸中測試")
lm(y~.,data = sim) %>% summary()
label  <- lm(y~.,data = sim) %>% predict(sim_2)
print("MSE")
mean((sim_2$y-label)^2)
print("xgboost")
xgb_test <- xgboost(data = data.matrix(sim[,-1]), 
label = sim[,"y"], 
eta = 0.5,
max_depth = 10, 
nround=25, 
subsample = 0.7,
colsample_bytree = 0.7,
objective = "reg:squarederror",
verbose = 0
)
label  <- predict(xgb_test,xgb.DMatrix(data.matrix(sim_2[,-1])))
print("MSE")
mean((sim_2$y-label)^2)

xgb.importance(model = xgb_test)

xgb.importance(model = xgb_test) %>% 
  xgb.plot.importance(top_n = 11)



```




```{r}
sim$y <- ifelse(sim$y>0,1,0)
sim_2$y <- ifelse(sim_2$y>0,1,0)
glm(y~.,family = binomial(),data = sim) %>% summary()
label  <- glm(y~.,family = binomial(),data = sim) %>% predict(sim_2,type="response")
Roc <- rocit(score=label,class=sim_2$y )

plot(Roc,values=F)

Cutoff <- which(Roc$FPR>=0.7) %>%
  min %>%
  Roc$Cutoff[.]
table(sim_2$y,label>Cutoff)


print("xgboost")
xgb_test <- xgboost(data = data.matrix(sim[,-1]), 
label = sim[,"y"], 
eta = 0.5,
max_depth = 10, 
nround=25, 
subsample = 0.7,
colsample_bytree = 0.7,
objective = "binary:logistic",
verbose = 0
)
label  <- predict(xgb_test,xgb.DMatrix(data.matrix(sim_2[,-1])))
Roc <- rocit(score=label,class=sim_2$y )

plot(Roc,values=F)


Cutoff <- which(Roc$FPR>=0.22) %>%
  min %>%
  Roc$Cutoff[.]
  
table(sim_2$y,label>Cutoff)
xgb.importance(model = xgb_test)

xgb.importance(model = xgb_test) %>% 
  xgb.plot.importance(top_n = 11)



```

### 第二次     

```{r}
set.seed(17423)
x <- rmvnorm(n = 1000,mean = c(0,0,0,0,0,0,0,0,0,0),sigma = diag(1,10))
set.seed(5997)
x_11 <- rnorm(n = 1000)
set.seed(515)
sd <- rnorm(1000,sd = 2)
y <- 10*x[,1]*x[,2]-7*x[,3]*x[,4]-8*x[,6]*x[,9]+sd
sim <- data.frame(y,x,x_11)


set.seed(12632)
x <- rmvnorm(n = 1000,mean = c(0,0,0,0,0,0,0,0,0,0),sigma = diag(1,10))
set.seed(5998)
x_11 <- rnorm(n = 1000)
set.seed(597)
sd <- rnorm(1000,sd = 2)
y <- 10*x[,1]*x[,2]-7*x[,3]*x[,4]-8*x[,6]*x[,9]+sd
sim_2 <- data.frame(y,x,x_11)
names(sim) <- c("y",paste0("x",1:11))
names(sim_2) <- c("y",paste0("x",1:11))
print("直接將生成的資料放進回歸中測試")
lm(y~.,data = sim) %>% summary()
label  <- lm(y~.,data = sim) %>% predict(sim_2)
print("MSE")
mean((sim_2$y-label)^2)
print("xgboost")
xgb_test <- xgboost(data = data.matrix(sim[,-1]), 
label = sim[,"y"], 
eta = 0.5,
max_depth = 10, 
nround=25, 
subsample = 0.7,
colsample_bytree = 0.7,
objective = "reg:squarederror",
verbose = 0
)
label  <- predict(xgb_test,xgb.DMatrix(data.matrix(sim_2[,-1])))
print("MSE")
mean((sim_2$y-label)^2)

xgb.importance(model = xgb_test)

xgb.importance(model = xgb_test) %>% 
  xgb.plot.importance(top_n = 11)



```




```{r}
sim$y <- ifelse(sim$y>0,1,0)
sim_2$y <- ifelse(sim_2$y>0,1,0)
glm(y~.,family = binomial(),data = sim) %>% summary()
label  <- glm(y~.,family = binomial(),data = sim) %>% predict(sim_2,type="response")
Roc <- rocit(score=label,class=sim_2$y )

plot(Roc,values=F)

Cutoff <- which(Roc$FPR>=0.1) %>%
  min %>%
  Roc$Cutoff[.]
table(sim_2$y,label>Cutoff)


print("xgboost")
xgb_test <- xgboost(data = data.matrix(sim[,-1]), 
label = sim[,"y"], 
eta = 0.5,
max_depth = 10, 
nround=25, 
subsample = 0.7,
colsample_bytree = 0.7,
objective = "binary:logistic",
verbose = 0
)
label  <- predict(xgb_test,xgb.DMatrix(data.matrix(sim_2[,-1])))
Roc <- rocit(score=label,class=sim_2$y )

plot(Roc,values=F)


Cutoff <- which(Roc$FPR>=0.25) %>%
  min %>%
  Roc$Cutoff[.]
  
table(sim_2$y,label>Cutoff)
xgb.importance(model = xgb_test)

xgb.importance(model = xgb_test) %>% 
  xgb.plot.importance(top_n = 11)



```


### 第三次    

```{r}
set.seed(1443)
x <- rmvnorm(n = 1000,mean = c(0,0,0,0,0,0,0,0,0,0),sigma = diag(1,10))
set.seed(5697)
x_11 <- rnorm(n = 1000)
set.seed(505)
sd <- rnorm(1000,sd = 2)
y <- 10*x[,1]*x[,2]-7*x[,3]*x[,4]-8*x[,6]*x[,9]+sd
sim <- data.frame(y,x,x_11)


set.seed(13232)
x <- rmvnorm(n = 1000,mean = c(0,0,0,0,0,0,0,0,0,0),sigma = diag(1,10))
set.seed(509)
x_11 <- rnorm(n = 1000)
set.seed(547)
sd <- rnorm(1000,sd = 2)
y <- 10*x[,1]*x[,2]-7*x[,3]*x[,4]-8*x[,6]*x[,9]+sd
sim_2 <- data.frame(y,x,x_11)
names(sim) <- c("y",paste0("x",1:11))
names(sim_2) <- c("y",paste0("x",1:11))
print("直接將生成的資料放進回歸中測試")
lm(y~.,data = sim) %>% summary()
label  <- lm(y~.,data = sim) %>% predict(sim_2)
print("MSE")
mean((sim_2$y-label)^2)
print("xgboost")
xgb_test <- xgboost(data = data.matrix(sim[,-1]), 
label = sim[,"y"], 
eta = 0.5,
max_depth = 10, 
nround=25, 
subsample = 0.7,
colsample_bytree = 0.7,
objective = "reg:squarederror",
verbose = 0
)
label  <- predict(xgb_test,xgb.DMatrix(data.matrix(sim_2[,-1])))
print("MSE")
mean((sim_2$y-label)^2)

xgb.importance(model = xgb_test)

xgb.importance(model = xgb_test) %>% 
  xgb.plot.importance(top_n = 11)



```




```{r}
sim$y <- ifelse(sim$y>0,1,0)
sim_2$y <- ifelse(sim_2$y>0,1,0)
glm(y~.,family = binomial(),data = sim) %>% summary()
label  <- glm(y~.,family = binomial(),data = sim) %>% predict(sim_2,type="response")
Roc <- rocit(score=label,class=sim_2$y )

plot(Roc,values=F)

Cutoff <- which(Roc$FPR>=0.3) %>%
  min %>%
  Roc$Cutoff[.]
table(sim_2$y,label>Cutoff)


print("xgboost")
xgb_test <- xgboost(data = data.matrix(sim[,-1]), 
label = sim[,"y"], 
eta = 0.5,
max_depth = 10, 
nround=25, 
subsample = 0.7,
colsample_bytree = 0.7,
objective = "binary:logistic",
verbose = 0
)
label  <- predict(xgb_test,xgb.DMatrix(data.matrix(sim_2[,-1])))
Roc <- rocit(score=label,class=sim_2$y )

plot(Roc,values=F)


Cutoff <- which(Roc$FPR>=0.3) %>%
  min %>%
  Roc$Cutoff[.]
  
table(sim_2$y,label>Cutoff)
xgb.importance(model = xgb_test)

xgb.importance(model = xgb_test) %>% 
  xgb.plot.importance(top_n = 11)



```




## 資料四(只有一個3變數的交互作用項)   

回歸表現得比XGboost還好，XGboost有大概抓到是那些變數。

$x_{1 \sim 10}\sim MN(\mu , \Sigma )$
$\mu=(0,0,0,0,0,0,0,0,0,0)$
$$\Sigma = \begin{pmatrix}
1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\ 
0 &  1& 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\ 
0 &  0& 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\ 
0 &  0& 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0\\ 
0 &  0& 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0\\ 
0 &  0& 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0\\ 
0 &  0& 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0\\ 
0 &  0& 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0\\ 
0 &  0& 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0\\ 
0 &  0& 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1
\end{pmatrix}$$  

$x_{11} \sim N(0,1)$      

$y=10x_1x_2x_3+\epsilon$

$\epsilon \sim N(0,4)$

### 第一次   

```{r}
set.seed(1423)
x <- rmvnorm(n = 1000,mean = c(0,0,0,0,0,0,0,0,0,0),sigma = diag(1,10))
set.seed(597)
x_11 <- rnorm(n = 1000)
set.seed(55)
sd <- rnorm(1000,sd = 2)
y <- 10*x[,1]*x[,2]*x[,3]+sd
sim <- data.frame(y,x,x_11)


set.seed(1232)
x <- rmvnorm(n = 1000,mean = c(0,0,0,0,0,0,0,0,0,0),sigma = diag(1,10))
set.seed(599)
x_11 <- rnorm(n = 1000)
set.seed(57)
sd <- rnorm(1000,sd = 2)
y <- 10*x[,1]*x[,2]*x[,3]+sd
sim_2 <- data.frame(y,x,x_11)
names(sim) <- c("y",paste0("x",1:11))
names(sim_2) <- c("y",paste0("x",1:11))
print("直接將生成的資料放進回歸中測試")
lm(y~.,data = sim) %>% summary()
label  <- lm(y~.,data = sim) %>% predict(sim_2)
print("MSE")
mean((sim_2$y-label)^2)
print("xgboost")
xgb_test <- xgboost(data = data.matrix(sim[,-1]), 
label = sim[,"y"], 
eta = 0.5,
max_depth = 10, 
nround=25, 
subsample = 0.7,
colsample_bytree = 0.7,
objective = "reg:squarederror",
verbose = 0
)
label  <- predict(xgb_test,xgb.DMatrix(data.matrix(sim_2[,-1])))
print("MSE")
mean((sim_2$y-label)^2)

xgb.importance(model = xgb_test)

xgb.importance(model = xgb_test) %>% 
  xgb.plot.importance(top_n = 11)



```




```{r}
sim$y <- ifelse(sim$y>0,1,0)
sim_2$y <- ifelse(sim_2$y>0,1,0)
glm(y~.,family = binomial(),data = sim) %>% summary()
label  <- glm(y~.,family = binomial(),data = sim) %>% predict(sim_2,type="response")
Roc <- rocit(score=label,class=sim_2$y )

plot(Roc,values=F)

Cutoff <- which(Roc$FPR>=0.35) %>%
  min %>%
  Roc$Cutoff[.]
table(sim_2$y,label>Cutoff)


print("xgboost")
xgb_test <- xgboost(data = data.matrix(sim[,-1]), 
label = sim[,"y"], 
eta = 0.5,
max_depth = 10, 
nround=25, 
subsample = 0.7,
colsample_bytree = 0.7,
objective = "binary:logistic",
verbose = 0
)
label  <- predict(xgb_test,xgb.DMatrix(data.matrix(sim_2[,-1])))
Roc <- rocit(score=label,class=sim_2$y )

plot(Roc,values=F)


Cutoff <- which(Roc$FPR>=0.4) %>%
  min %>%
  Roc$Cutoff[.]
  
table(sim_2$y,label>Cutoff)
xgb.importance(model = xgb_test)

xgb.importance(model = xgb_test) %>% 
  xgb.plot.importance(top_n = 11)



```

### 第二次     

```{r}
set.seed(17423)
x <- rmvnorm(n = 1000,mean = c(0,0,0,0,0,0,0,0,0,0),sigma = diag(1,10))
set.seed(5997)
x_11 <- rnorm(n = 1000)
set.seed(515)
sd <- rnorm(1000,sd = 2)
y <- 10*x[,1]*x[,2]*x[,3]+sd
sim <- data.frame(y,x,x_11)


set.seed(12632)
x <- rmvnorm(n = 1000,mean = c(0,0,0,0,0,0,0,0,0,0),sigma = diag(1,10))
set.seed(5998)
x_11 <- rnorm(n = 1000)
set.seed(597)
sd <- rnorm(1000,sd = 2)
y <- 10*x[,1]*x[,2]*x[,3]+sd
sim_2 <- data.frame(y,x,x_11)
names(sim) <- c("y",paste0("x",1:11))
names(sim_2) <- c("y",paste0("x",1:11))
print("直接將生成的資料放進回歸中測試")
lm(y~.,data = sim) %>% summary()
label  <- lm(y~.,data = sim) %>% predict(sim_2)
print("MSE")
mean((sim_2$y-label)^2)
print("xgboost")
xgb_test <- xgboost(data = data.matrix(sim[,-1]), 
label = sim[,"y"], 
eta = 0.5,
max_depth = 10, 
nround=25, 
subsample = 0.7,
colsample_bytree = 0.7,
objective = "reg:squarederror",
verbose = 0
)
label  <- predict(xgb_test,xgb.DMatrix(data.matrix(sim_2[,-1])))
print("MSE")
mean((sim_2$y-label)^2)

xgb.importance(model = xgb_test)

xgb.importance(model = xgb_test) %>% 
  xgb.plot.importance(top_n = 11)



```




```{r}
sim$y <- ifelse(sim$y>0,1,0)
sim_2$y <- ifelse(sim_2$y>0,1,0)
glm(y~.,family = binomial(),data = sim) %>% summary()
label  <- glm(y~.,family = binomial(),data = sim) %>% predict(sim_2,type="response")
Roc <- rocit(score=label,class=sim_2$y )

plot(Roc,values=F)

Cutoff <- which(Roc$FPR>=0.65) %>%
  min %>%
  Roc$Cutoff[.]
table(sim_2$y,label>Cutoff)


print("xgboost")
xgb_test <- xgboost(data = data.matrix(sim[,-1]), 
label = sim[,"y"], 
eta = 0.5,
max_depth = 10, 
nround=25, 
subsample = 0.7,
colsample_bytree = 0.7,
objective = "binary:logistic",
verbose = 0
)
label  <- predict(xgb_test,xgb.DMatrix(data.matrix(sim_2[,-1])))
Roc <- rocit(score=label,class=sim_2$y )

plot(Roc,values=F)


Cutoff <- which(Roc$FPR>=0.5) %>%
  min %>%
  Roc$Cutoff[.]
  
table(sim_2$y,label>Cutoff)
xgb.importance(model = xgb_test)

xgb.importance(model = xgb_test) %>% 
  xgb.plot.importance(top_n = 11)



```


### 第三次    

```{r}
set.seed(1443)
x <- rmvnorm(n = 1000,mean = c(0,0,0,0,0,0,0,0,0,0),sigma = diag(1,10))
set.seed(5697)
x_11 <- rnorm(n = 1000)
set.seed(505)
sd <- rnorm(1000,sd = 2)
y <- 10*x[,1]*x[,2]*x[,3]+sd
sim <- data.frame(y,x,x_11)


set.seed(13232)
x <- rmvnorm(n = 1000,mean = c(0,0,0,0,0,0,0,0,0,0),sigma = diag(1,10))
set.seed(509)
x_11 <- rnorm(n = 1000)
set.seed(547)
sd <- rnorm(1000,sd = 2)
y <- 10*x[,1]*x[,2]*x[,3]+sd
sim_2 <- data.frame(y,x,x_11)
names(sim) <- c("y",paste0("x",1:11))
names(sim_2) <- c("y",paste0("x",1:11))
print("直接將生成的資料放進回歸中測試")
lm(y~.,data = sim) %>% summary()
label  <- lm(y~.,data = sim) %>% predict(sim_2)
print("MSE")
mean((sim_2$y-label)^2)
print("xgboost")
xgb_test <- xgboost(data = data.matrix(sim[,-1]), 
label = sim[,"y"], 
eta = 0.5,
max_depth = 10, 
nround=25, 
subsample = 0.7,
colsample_bytree = 0.7,
objective = "reg:squarederror",
verbose = 0
)
label  <- predict(xgb_test,xgb.DMatrix(data.matrix(sim_2[,-1])))
print("MSE")
mean((sim_2$y-label)^2)

xgb.importance(model = xgb_test)

xgb.importance(model = xgb_test) %>% 
  xgb.plot.importance(top_n = 11)



```




```{r}
sim$y <- ifelse(sim$y>0,1,0)
sim_2$y <- ifelse(sim_2$y>0,1,0)
glm(y~.,family = binomial(),data = sim) %>% summary()
label  <- glm(y~.,family = binomial(),data = sim) %>% predict(sim_2,type="response")
Roc <- rocit(score=label,class=sim_2$y )

plot(Roc,values=F)

Cutoff <- which(Roc$FPR>=0.6) %>%
  min %>%
  Roc$Cutoff[.]
table(sim_2$y,label>Cutoff)


print("xgboost")
xgb_test <- xgboost(data = data.matrix(sim[,-1]), 
label = sim[,"y"], 
eta = 0.5,
max_depth = 10, 
nround=25, 
subsample = 0.7,
colsample_bytree = 0.7,
objective = "binary:logistic",
verbose = 0
)
label  <- predict(xgb_test,xgb.DMatrix(data.matrix(sim_2[,-1])))
Roc <- rocit(score=label,class=sim_2$y )

plot(Roc,values=F)


Cutoff <- which(Roc$FPR>=0.6) %>%
  min %>%
  Roc$Cutoff[.]
  
table(sim_2$y,label>Cutoff)
xgb.importance(model = xgb_test)

xgb.importance(model = xgb_test) %>% 
  xgb.plot.importance(top_n = 11)



```